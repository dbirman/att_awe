"The way we think people perform this task is that the difference in response is important and noise--in the behavioral model we're going to freeze the noise". The shapes of the functions youg et out are constrained by the discrimination performance, steeper discrimination = larger responses, but noise & your model of noise will also shape these--we'll come back to that.

"There's different variations of these models we're going to test"

Stick very carefully to actual data

***Ten Second Version***

What we did here was test the idea that discriminating changes in the intensity of motion and visual contrast your brain might be using the same strategy.

***Three Minute Version***

So what we did here was take a set of behavioral measurements and a set of fMRI measurements each for contrast and motion coherence discrimination. Then we looked to see whether we might be able to link these together using a single model. We first measured how large of an increment subjects need to discriminate different intensities of contrast and motion coherence: for example, we might show someone 30% contrast on one side and 30 + a little extra on the other, and what we're looking to find is the "just noticeable difference". You can see these in the plot on the right, where for both features as the base stimulus increases, the just noticeable differences do as well. The second thing we did was record fMRI measurements while subjects viewed the same stimuli. The shorty story here is that in early visual areas like V1 we see sensitivty to contrast, but we don't see that in higher areas like MT. And in our data the opposite is true for motion coherence--MT is sensitive to that feature, while V1 and early areas are insensitive. We have a lot of data from a lot of conditions here, but that's the key point to take with you. 

Now the goal is to link behavior to the cortical measurements. So the way we do that is by estimating from either set of data a model of underlying neural responses. So for example to do this in behavior we're basically looking at the shape of the underlying functions, and whether they accurately reconstruct the just noticeable differences we observed. Simlarly for the fMRI we take the underlying function and then use it to reconstruct the fMRI data. So given our data from above we can find the maximum likelihood response functions, which are shown in this center panel. As you can see there's some similarity between the fMRI responses and those that we get from the behavior--but importantly either set of data alone doesn't let us distinguish between different variations of the response functions e.g. whether they are linear or non-linear, and whether the noise is linear or non-linear. We show all of these possibilities in this bottom panel here, and as you can see the main difference ends up being the shapes of the functions and their magnitudes.

So the last step now is to make the final link. This involves scaling the functions from each set of data to fit each other, and it turns out that the scaling factor corresponds to an estimate of how much neural noise there is. So in the panel on the left we've made that scaling happen--and specifically we scale the response model based on contrast discrimination to V1, because there's evidence from previous work that these might be tied together. The end result is that this does work, it suggests that MT might be the best candidate region. So to bring us back to the original goal: can the same approach be sufficient for both contrast and motion coherence? It looks like it's possible, and in our data it suggests that both sets of response functions are non-linear, while the neural noise is additive.

***Ten Minute Version***

-Task-

First we're going to measure subject's ability to discriminate contrast and motion coherence, to do that we had them perform a 2-alt forced choice discrimination task. We're using contrast because previous work has made a connection between early visual cortex and contrast discrimination, we're using motion because we're interested in random dot displays and how they might be represented.

So we asked participants to discriminate one feature at a time. To do this they were they shown two patches of dots at low contrast and incoherent motion, which they adapted to. At the start of each trial both patches increased in contrast and motion, and after a brief delay the participants made a response indicating which patch increased the most. They were given immediate feedback.

In the right panel you can see the behavior of a single subject. To orient you the X axis indicates the difference in stimulus strength between the right and left dot patches, so you should expect a high percentage of right choices on the right side of the plot. As you can see subjects were able to focus on each feature without much interference from the feature that they were asked to ignore. Also note that the slope on the motion coherence plot is less steep, indicating that subjects needed stronger stimuli to discriminate motion compared to contrast.

Next I want to show you the cortical responses we collected, and we'll come back to how we interpret the behavioral data.

-Cortical-

So we made two sets of cortical measurements, we measured responses while subjects performed the discrimination task, and we also measured a much larger set of data including shorter and longer stimulus lengths, and a larger range of contrast and motion coherence strengths. I'll focus on that latter larger set of passive viewed stimuli because they give us a larger range of data to work with for our models.

To give you a sense of the magnitude of cortical responses we observed we pulled out two slices of the full set of data, which are shown at the top right. These are the conditions where only one feature changed. What you should be able to see here is the asymmetry in sensitivity between MT and V1: V1 is highly sensitive to changes in contrast while MT is not. In this slice you'll also notice that MT and V1 look equally sensitive to motion coherence.

Explain grid: But if you look at the full grid of V1 responses (mid-left), you'll see that in the conditions where contrast changed there's no effect of motion coherence. ***EXPLAIN*** Let me unpack that: what we're showing here are the individual responses for a variety of conditions. 
MT meanwhile is always sensitive to motion coherence even when contrast changed.

-Linking Model-

***Stronger statement here: *be very direct*, "We're going to test different models to see whether the behavioral data and cortical responses match. We're going to look for different areas that match under different model assumptions." We use models that connect responses to behavior and look for which models these two things align.***

So, what we'd really like to do here is connect behavior to cortical responses. And to understand how the behavior and cortical responses connect to each other we put together a model that links the two by estimating the "stimulus response functions", these are a model of how neurons in visual cortex might respond to changes in features strength. Based on previous work we know that contrast response functions (e.g. in V1) in the range we're interested in look like saturating non-linear functions, so we use this as a basis. So first we'll go through how we get from one of these functions to a model of the behavior:

(Behavior)
Given some particular stimulus response function shape and a value for noise you can sample the "response" on any particular trial. We model this as the change in the response function from the adapted stimulus strength to that particular trial's stimulus strength, plus noise sampled from a gaussian. So for a given trial then the probability of responding "right" will end up being the difference between the sampled left and right responses, plus any biases the subject has: e.g. a bias to respond right, or a bias to stay rather than switch responses. So this gets us back into the same space we showed you earlier, where we can convert from any particular difference in stimulus strength to a percentage of right choices.

So that's half of the linking model, so to speak, and now we need to be able to go in the other direction to get from the stimulus response functions to our cortical response data.

(Cortical)
To do this the first step looks the same, but notice that there's now no sampling from a distribution because we don't need to go into a space of probabilities of choices. Instead we're going to build up a standard GLM by first making a timeseries where each trial's magnitude is the sum of some constant trial onset effect and the response due to the stimulus strength shown on that trial. To get into fMRI space we then simply convolve with an estimate of the hemodynamic response function. 

(Responses)
In practice we reverse these generative models to estimate the underlying stimulus response functions from either the behavior or the fMRI data--these are the plots shown to the right. Notice that in the behavioral plot the magnitude of contrast response functions is larger--as I mentioned before this is because subjects discriminate contrast better than motion coherence, so when constraining on the behavior this has to be the outcome. Looking at the fMRI constrained functions you should notice that these look relatively similar to the behavior constrained functions, but we'll make a more formal comparison of these later. Before we go on note that the responses in both sets of data come out slightly non-linear.

(JND)
The reason for this is that in the behavioral data the "just noticeable differences" we observed are slightly increasing with increasing base stimulus strength. Let me unpack that a bit before we go on: the "just noticeable difference" is basically how much of an increase in response you need before a participant will notice the difference consistently. We define consistently here as a response increase equal to noise, which is also equivalent to a d' of 1. If the stimulus response functions were perfectly linear then just noticeable differences should be consistent regardless of what stimulus strength you start one. But instead, we observed increasing values--this suggests that either the response functions saturate at high values OR the noise increases with stimulus strength. Take a look at the bottom panel: you'll see here the optimal contrast and motion coherence response functions under these different regimes: linear or non-linear responses, combined with additive (constant) or poisson (increasing) noise. As you can see the magnitude of the poisson models is much larger, this is because the noise scales as the square root of the responses.

-Sigma-
So the last thing we want to do now is come back to our original question: can we explain both contrast and motion coherence with this same model, but different brain regions? To get this final step we have to scale the neural response functions into the space of the behavioral response functions, so that we can use them to reconstruct the behavior. We do this by fitting the amount of neural noise that would have to surround these functions to match them to the behavioral functions. Because previous work has shown that contrast discrimination might depend on early visual cortex responses we constrained our noise estimate on only the behavioral response function for contrast and the response function for V1. As you can see this approach approximates the V1 response reasonably well, although the ability to discriminate among our subjects appears to be better than the V1 estimated response functino woudl allow. Looking at coherence discrimination you can see that the only region that comes close to supporting motion coherence discrimination is MT. Also on this plot you can see that the different models fit more or less well to the fMRI response functions, we've summarized the evidence for or against models in the plot on the right, comparing to the BIC of the non-linear additive model all of the models are significantly worse. We also have here the different estimates of the standard deviation of the neural noise, which you can compare to the standard deviation of the actual fMRI data, approximately 4%. Across our four models this means that neural noise might range between one percent to one tenth of a percent of the full variability in the data.

-Conclusion-

So to summarize quickly: We found that the same signal detection model is sufficient to explain contrast and motion coherence discrimination based on signals in V1 and MT respectively.

Thank you!